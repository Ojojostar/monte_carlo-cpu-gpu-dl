{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning model time!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<img src = pics/OIP.jpg width = 400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "cupy.cuda.set_allocator(None)       # no clue\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "\n",
    "import numba\n",
    "from numba import cuda\n",
    "\n",
    "import os, os.path\n",
    "from pathlib import Path\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset\n",
    "Each monte carlo simulation run is equivalent to one data point being made, so to generate a large dataset, we have to run monte carlo simulations lots of times, and batches can hypotheitcally make doing this faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here,the mc model from mc_snow, cuda version was imported and cleaned up a bit.\n",
    "note that due to the existence of batches, some of the varaibles now need a bit of extra finagling to access properly. (s_0, Ki, Ko, mu, sigma, pot,r, d_normals, snowball_path_holder). Overall design is very close to original, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit               # defualt GPU\n",
    "def monte_carlo_andtheholygrail_gpu(d_s, s_0, Ki, Ko, mu, sigma, pot,r,\n",
    "                                    d_normals, snowball_path_holder, MONTHS,\n",
    "                                    N_STEPS, N_PATHS, N_BATCH):\n",
    "    \n",
    "\n",
    "    # for shared memory (non)optimization\n",
    "    # shared = cuda.shared.array(shape=0, dtype=numba.float32)\n",
    "    # # load to shared memory\n",
    "    # path_offset = cuda.blockIdx.x * cuda.blockDim.x\n",
    "\n",
    "    # ii - overall thread index\n",
    "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
    "\n",
    "    for n in range(ii, N_PATHS * N_BATCH, stride):\n",
    "        # newly added vars for N_BATCH calculations\n",
    "        batch_id = n // N_PATHS\n",
    "        path_id = n % N_PATHS       # equivalent to n in old code \n",
    "\n",
    "        snowball_path_holder[n][0] = s_0[batch_id]\n",
    "        earlyexit = False\n",
    "        ki = False\n",
    "        mald = False\n",
    "        for t in range(N_STEPS):\n",
    "            # pre shared memory b_motion    \n",
    "            #                                                   \n",
    "            b_motion = d_normals[path_id + batch_id * N_PATHS +  t * N_PATHS * N_BATCH]\n",
    "\n",
    "            # post shared memory b_motion\n",
    "            # shared[cuda.threadIdx.x] = d_normals[path_offset + cuda.threadIdx.x + t * N_PATHS]\n",
    "\n",
    "            dt = 1/N_STEPS\n",
    "            # pre shared memory b_motion\n",
    "            ds = snowball_path_holder[n][t] * mu[batch_id] * dt + snowball_path_holder[n][t] \\\n",
    "                                                * sigma[batch_id] * b_motion * math.sqrt(dt) \n",
    "            # post shared memory b_motion\n",
    "            # ds = snowball_path_holder[n][t] * mu[batch_id] * dt + snowball_path_holder[n][t] * sigma[batch_id] * shared[cuda.threadIdx.x] * math.sqrt(dt) \n",
    "                    # no adjusting list sizes in cuda :(\n",
    "                    \n",
    "            snowball_path_holder[n][t+1] = snowball_path_holder[n][t] + ds\n",
    "            \n",
    "            if snowball_path_holder[n][t+1] <= Ki[batch_id]:\n",
    "                ki = True\n",
    "\n",
    "            if not mald:\n",
    "                for month in (0,1,2,3,4,5,6,7,8,9,10,11):                # need to do this instead because contains (in) and range are disabled\n",
    "                    if t+1 == MONTHS[month]:     #startday no longer used to fake a start date in code\n",
    "                        if snowball_path_holder[n][t+1] >= Ko[batch_id]:\n",
    "                            price =  pot[batch_id] * t/365     # should turn t into int\n",
    "                            # return snowball_path, price\n",
    "                            d_s[n] =  price * math.exp(-r[batch_id] * t/N_STEPS)   # accounting for r\n",
    "                            snowball_path_holder[n][-1] = d_s[n]            \n",
    "                            earlyexit = True\n",
    "                            mald = True\n",
    "                            break\n",
    "            else: # if mald\n",
    "                break\n",
    "        \n",
    "        if not earlyexit:       # to prevent early exit getting out of bdds error\n",
    "            # did not get knocked up or down\n",
    "            price = pot[batch_id]\n",
    "            if ki and snowball_path_holder[n][N_STEPS] <= s_0[batch_id]:          # blo got knocked down and never recovered\n",
    "                price = snowball_path_holder[n][N_STEPS] - s_0[batch_id]\n",
    "            elif ki and snowball_path_holder[n][N_STEPS] <= Ko[batch_id]:          # blo got knocked down for a bit but finished above Ki\n",
    "                price =0\n",
    "            d_s[n] = price * math.exp(-r[batch_id])\n",
    "            snowball_path_holder[n][-1] = d_s[n]    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for some reason, increasing the number of paths and/or the number of batches greatly slows down my monte's carlo's computational speed. I have no definitive proof that this is the case, but I strongly belive it to be because threads are becoming unsynched as the code runs on, making both greater paths and greater batches than my current settings have much slower run times than their current values. Not that my current code isn't slower than it should be, either. <br>\n",
    " Max len controls the number of data points, path controls how accurate each data point is. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished running, data is saved into a directory.\n",
    "<br>\n",
    "If you think running a large number like 1 mil mcs takes way too long, throw these first three cells into a python file (datasetgen.py) and let it run in its own terminal while going forward in the notebook with a smaller set for test purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for demonstration purposes, only a small amount of data is generated here. If large amounts of data are to be generated, **PLEASE** go to ***datasetgen.py*** instead. there is much more stuff there that isnt incorporated here since i dont like scrolling htat much that would make generating data a bit easier (generates data in chunks so that its safer, ability to run mutliple process of program at the same time thru currnumm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding files starting from 101\n",
      "Num batches: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.882806777954102]\n",
      "[2.3875019550323486]\n",
      "[5.110105991363525]\n",
      "[2.0633299350738525]\n",
      "[2.978761672973633]\n",
      "[2.733570098876953]\n",
      "[2.55251407623291]\n",
      "[2.243455648422241]\n",
      "[2.852839469909668]\n",
      "[3.885261058807373]\n",
      "time 2.7585599422454834 v 3.885261 avg time 5.517119884490967e-06\n",
      "[]\n",
      "tensor([])\n",
      "tensor([])\n"
     ]
    }
   ],
   "source": [
    "#               make sure max_len is large enough or else divide by zero error occurs (at least 100 batches must be run)\n",
    "limiter = True\n",
    "# max_len = 1000000              \n",
    "max_len = 10                 # test value\n",
    "number_path = 500000\n",
    "batch = 1\n",
    "threads = 256\n",
    "seed  =1999 \n",
    "num = 0\n",
    "max_length = max_len\n",
    "N_PATHS = number_path\n",
    "N_STEPS = 365\n",
    "N_BATCH  =batch\n",
    "\n",
    "max_length = max_length // N_BATCH\n",
    "percenter  =100\n",
    "percent = max_length // percenter\n",
    "\n",
    "#           uncomment if u want less batches, the percent will just be wrong\n",
    "if percent == 0:\n",
    "    percent = 1\n",
    "\n",
    "# we will not be calculating a starting date since the difference is negligible and I aint rigging up\n",
    "# a system to check if a certain day is a weekend or not\n",
    "MONTHS = cupy.asnumpy([0, 31,59,90,120,151,181,212,243, 273,304,334])\n",
    "snowball_path_holder =  np.zeros(N_BATCH*N_PATHS, dtype=(np.float32,N_STEPS+1))\n",
    "output = cupy.zeros(N_BATCH*N_PATHS, dtype = cupy.float32)\n",
    "num_blocks  =(N_PATHS * N_BATCH -1) // threads +1\n",
    "num_threads = threads\n",
    "\n",
    "Xss = []\n",
    "Yss = []\n",
    "\n",
    "currnum = len(os.listdir('snow_data_tensor_train'))//2+1\n",
    "print(\"Adding files starting from\", currnum)\n",
    "\n",
    "print(\"Num batches:\", N_BATCH)\n",
    "\n",
    "# making sure self.snowball_path_holder is zeroed to avoid bug\n",
    "# self.snowball_path_holder.fill(0)\n",
    "s = time.time()\n",
    "\n",
    "for i in range(1,max_length+1):\n",
    "        randoms = cupy.random.normal(0,1, N_BATCH * N_PATHS * N_STEPS, dtype= cupy.float32)\n",
    "\n",
    "        Xpre = cupy.random.rand(N_BATCH, 7, dtype = cupy.float32)\n",
    "        #                        s_0,  Ki, Ko,  mu, sigma, pot, r\n",
    "        Xpre = Xpre * cupy.array([4,  -2,  1,  .01,  .15,  10, .01], dtype=cupy.float32)\n",
    "        X = Xpre +    cupy.array([8,   0,  0,  .02, .275,  15, .02], dtype=cupy.float32)\n",
    "        # Ki and Ko will be set down here instead of the previous line to make them relative to s_0.\n",
    "        X[:, 1] = X[:,0] -1         # overriding Ki and Ko \n",
    "        X[:, 2] = X[:,0] -.2        \n",
    "        X[:, 1] += Xpre[:,1]        # adding back the offset in Xpre after it gets overrided\n",
    "        X[:, 2] += Xpre[:,2] \n",
    "\n",
    "        snowball_path_holder.fill(0)\n",
    "                                        # d_s, s_0, Ki, Ko, mu, sigma, pot,r,\n",
    "                                        # d_normals, snowball_path_holder, MONTHS,\n",
    "                                        # N_STEPS, N_PATHS, N_BATCH):\n",
    "        monte_carlo_andtheholygrail_gpu[(num_blocks,), (num_threads,)](\n",
    "                                        output, X[:, 0], X[:, 1], X[:, 2], X[:, 3], \n",
    "                                        X[:, 4], X[:, 5], X[:, 6],\n",
    "                                        randoms, snowball_path_holder, MONTHS,\n",
    "                                        N_STEPS, N_PATHS, N_BATCH)\n",
    "        # o = output.reshape(N_BATCH, N_PATHS)\n",
    "        # Y  =o.mean(axis =1)         # getting the average of each batch\n",
    "        Y = output.mean()\n",
    "        # Y = output\n",
    "        X = X.mean(axis=0)\n",
    "        Xss.append(X.tolist())\n",
    "        Yss.append(Y.tolist())\n",
    "        print(Yss)\n",
    "        # Xss.append(X)\n",
    "        # Yss.append(Y)\n",
    "\n",
    "        # have following turned off. go to datasetgen.py for a better view.\n",
    "        # if(i%percent==0):\n",
    "        #     if limiter:\n",
    "        #         if currnum > percenter:\n",
    "        #             print(\"premature exit, burunyu~\")\n",
    "        #             break\n",
    "        #     e = time.time()\n",
    "        #     print(i/(percent), \"percent of the way there! Time is now:\", (e-s)/60/60, \"hours\")\n",
    "        #     # print(i/(percent*10), \"percent of the way there! Time is now:\", e-s, \"secs\")\n",
    "        #     print(\"now saving tsnowX_{}.pt\".format(currnum) )\n",
    "        #     tensorX = np.array(Xss)\n",
    "        #     tensorY = np.array(Yss)\n",
    "        #     tensorX = torch.Tensor(tensorX)\n",
    "        #     tensorY = torch.Tensor(tensorY)\n",
    "        #     torch.save(tensorX, f\"snow_data_tensor_train/tsnowX_{currnum}.pt\")\n",
    "        #     torch.save(tensorY, f\"snow_data_tensor_train/tsnowY_{currnum}.pt\")\n",
    "        #     Xss.clear()\n",
    "        #     Yss.clear()\n",
    "        #     currnum += 1\n",
    "\n",
    "        num+=1          #actually useless\n",
    "        # print((from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))) \n",
    "        \n",
    "        Xss.clear()\n",
    "        Yss.clear()\n",
    "\n",
    "v = output.mean()\n",
    "cuda.synchronize()\n",
    "e = time.time()\n",
    "print('time', e-s, 'v', v, 'avg time', (e-s)/500000)\n",
    "\n",
    "## i have following turned off but feel free to do stuff with it\n",
    "\n",
    "# torch.save(tensorX, \"snow_data_tensor_train/tsnowX.pt\")\n",
    "# torch.save(tensorY, \"snow_data_tensor_train/tsnowY.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A small tangent on datasetgen\n",
    "So... after a lot of finagling with datasetgen.py, I have realized that it is most certianly the case that the code runs slower due to needing to run 500000 paths before it can synch back up again, causing great slowdown, espeicaly with larger batch/path numbers. However, this does not prevent us from running multiple different processes of the same code, filling up the gpu with power of more processes instead. Though there is some slowdown caused by having more processes, there is an almost 2 times improvement over runnign one process of the code when using 3 processes. Thats a lot! Of course, if you can get more processes runnign without gpu's memory going to 100% and locking up the program for extended periods of time, this should allow for as much speedup as you would get by using all of your gpu???? I think???? Ive been runnign datasetgen in its own power shells to prevent restarts of vs code from restarting it (pylance keeps crashing >:( ), but this can obviously be turned all into a single program that creates as many processes as you want! Therefore there is also datasetgen_multi.py which can do exactly that! its a slight modification of datasetgen.py but is a big quality of life update, greatly lowering the amount of power shells i need to open every time i run the program (u cant close em while they are runnign since they are locked in and dont like to stop at keyboard interrupts)\n",
    "\n",
    "<img src = pics\\big_scary_hacker_man.jpg width = 700> <br>\n",
    "\n",
    "**Fig 1. Me being big scary hacker man ðŸ˜±** (6 process was a mistake and now all of them are frozen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to regularly scheduled programming (loading dataset made by **datasetgen(_multi).py**)\n",
    "Loading the data to confirm its existence! turning it into gpu monsters to prepare for throwing it into model to train! can prolly be done be done before saving, thouhg :/ <br>\n",
    "oh well, it takes like no time to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0785e+01, 9.7630e+00, 1.0941e+01,  ..., 4.1676e-01, 1.8827e+01,\n",
      "         2.7015e-02],\n",
      "        [1.1214e+01, 8.3553e+00, 1.1372e+01,  ..., 2.9712e-01, 1.7451e+01,\n",
      "         2.6089e-02],\n",
      "        [8.1927e+00, 6.3303e+00, 8.4115e+00,  ..., 4.1421e-01, 2.0627e+01,\n",
      "         2.6026e-02],\n",
      "        ...,\n",
      "        [8.1546e+00, 5.6825e+00, 8.4402e+00,  ..., 4.2203e-01, 2.1776e+01,\n",
      "         2.4651e-02],\n",
      "        [9.7141e+00, 7.2488e+00, 9.5389e+00,  ..., 2.9207e-01, 2.4110e+01,\n",
      "         2.0016e-02],\n",
      "        [8.2834e+00, 5.3780e+00, 8.1775e+00,  ..., 2.8856e-01, 1.7493e+01,\n",
      "         2.0874e-02]])\n",
      "torch.Size([4997559, 7])\n",
      "tensor([2.2016, 2.8075, 2.7976,  ..., 3.4159, 3.4042, 3.5705])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms, utils, datasets\n",
    "import os\n",
    "\n",
    "path = \"snow_data\"\n",
    "\n",
    "finnum = len(os.listdir(f\"{path}\"))//2+1          # equivalent to currnum\n",
    "\n",
    "tensor_x_L = torch.load(f\"{path}/tsnowX_1.pt\")\n",
    "tensor_y_L = torch.load(f\"{path}/tsnowY_1.pt\")\n",
    "\n",
    "\n",
    "for tensor_num  in range(2, finnum):\n",
    "    tensor_x_R = torch.load(f\"{path}/tsnowX_{tensor_num}.pt\")\n",
    "    tensor_y_R = torch.load(f\"{path}/tsnowY_{tensor_num}.pt\")   \n",
    "\n",
    "    #   cat left side with right side (kiara and kamma???)\n",
    "    tensor_x_L = torch.cat((tensor_x_L, tensor_x_R), 0)\n",
    "    tensor_y_L = torch.cat((tensor_y_L, tensor_y_R), 0)\n",
    "\n",
    "print(tensor_x_L)\n",
    "print(tensor_x_L.size())\n",
    "print(tensor_y_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also split the data into more train, validation, and test before saving once more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_data = tensor_x_L.size()[0]\n",
    "num_train = int(num_data*.6)\n",
    "num_val = int(num_data*.8)\n",
    "\n",
    "train_x, val_x, test_x = torch.tensor_split(tensor_x_L, (num_train, num_val))\n",
    "train_y, val_y, test_y = torch.tensor_split(tensor_y_L, (num_train, num_val))\n",
    "\n",
    "# print(train.size())\n",
    "\n",
    "\n",
    "dir_p = \"snow_data_processed\"\n",
    "\n",
    "torch.save(train_x, f\"{dir_p}\\\\train_x.pt\")\n",
    "torch.save(val_x, f\"{dir_p}\\\\val_x.pt\")\n",
    "torch.save(test_x, f\"{dir_p}\\\\test_x.pt\")\n",
    "\n",
    "torch.save(train_y, f\"{dir_p}\\\\train_y.pt\")\n",
    "torch.save(val_y, f\"{dir_p}\\\\val_y.pt\")\n",
    "torch.save(test_y, f\"{dir_p}\\\\test_y.pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to load the processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "dir_p = \"snow_data_processed\"\n",
    "batch_size = 100\n",
    "\n",
    "train_x = torch.load(f\"{dir_p}\\\\train_x.pt\")\n",
    "train_y = torch.load(f\"{dir_p}\\\\train_y.pt\")\n",
    "\n",
    "test_x = torch.load(f\"{dir_p}\\\\test_x.pt\")\n",
    "test_y = torch.load(f\"{dir_p}\\\\test_y.pt\")\n",
    "\n",
    "val_x = torch.load(f\"{dir_p}\\\\val_x.pt\")\n",
    "val_y = torch.load(f\"{dir_p}\\\\val_y.pt\")\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tr_set = TensorDataset(train_x.float().to(device),train_y.float().to(device)) # create your datset\n",
    "te_set = TensorDataset(test_x.float().to(device),test_y.float().to(device)) \n",
    "val_set = TensorDataset(val_x.float().to(device),val_y.float().to(device)) \n",
    "\n",
    "tr_loader = DataLoader(tr_set, batch_size)\n",
    "te_loader = DataLoader(te_set, batch_size)\n",
    "val_loader = DataLoader(val_set, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for some reason, the guy who made the nvidia notebook decided it was a good idea to make the dataset generate itself while training, making the training process significantly slower than if the data was already prepared already. This works, but is not that good. I would not reccomend, 2/5 stars. <br>\n",
    "edit: he does it the better way in their next notbook :/<br>\n",
    "still leaving this in since its interesting to look at tho. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SnowballDataSet(object):\n",
    "\n",
    "    def __init__(self, max_len = 10, number_path = 1000, batch = 2, threads = 512, seed  =1999 ):\n",
    "        self.num = 0\n",
    "        self.max_length = max_len\n",
    "        self.N_PATHS = number_path\n",
    "        self.N_STEPS = 365\n",
    "        self.N_BATCH  =batch\n",
    "        # we will not be calculating a starting date since the difference is negligible and I aint rigging up\n",
    "        # a system to check if a certain day is a weekend or not\n",
    "        self.MONTHS = cupy.asnumpy([0, 31,59,90,120,151,181,212,243, 273,304,334])\n",
    "                # SHOULD THIS BE NP ARRAY INSTEAD????\n",
    "        self.snowball_path_holder =  np.zeros(self.N_BATCH*self.N_PATHS, dtype=(np.float32,self.N_STEPS+1))# extra 1 is no longer for storing payoff\n",
    "        # self.snowball_path_holder = cupy.array(self.snowball_path_holder)\n",
    "        # self.T  = np.float(365.0)         # nah id lose. \n",
    "        self.output = cupy.zeros(self.N_BATCH*self.N_PATHS, dtype = cupy.float32)\n",
    "        self.num_blocks  =(self.N_PATHS * self.N_BATCH -1) // threads +1\n",
    "        self.num_threads = threads\n",
    "\n",
    "        #  temp_months, snowball_path_holder both added now\n",
    "        cupy.random.seed(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.max_length\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.num = 0\n",
    "        return self\n",
    "\n",
    "    #   next basically takes the place of the cell running the mc. As such need to generate\n",
    "     # (d_s, s_0, Ki, Ko, mu, sigma,  pot,r, d_normals, snowball_path_holder, MONTHS, N_STEPS, N_PATHS, N_BATCH\n",
    "     # note that all but s_0, Ki, Ko, mu, sigma,  pot,r, d_normals have been generated in init due to their nonrandom nature\n",
    "    def __next__(self):\n",
    "        if self.num > self.max_length: \n",
    "            raise StopIteration      # nvidia notebook uses raise StopIteration here but p sure its deprecated???\n",
    "                                      # is used because return returns an extra None\n",
    "        # generating the variables\n",
    "        # d_normals\n",
    "        randoms = cupy.random.normal(0,1, self.N_BATCH * self.N_PATHS * self.N_STEPS, dtype= cupy.float32)\n",
    "\n",
    "        Xpre = cupy.random.rand(self.N_BATCH, 7, dtype = cupy.float32)\n",
    "        #                        s_0,  Ki, Ko,  mu, sigma, pot, r\n",
    "        Xpre = Xpre * cupy.array([4,  -2,  1,  .01,  .15,  10, .01], dtype=cupy.float32)\n",
    "        X = Xpre +    cupy.array([8,   0,  0,  .02, .275,  15, .02], dtype=cupy.float32)\n",
    "        \n",
    "        # Ki and Ko will be set down here instead of the previous line to make them relative to s_0.\n",
    "        X[:, 1] = X[:,0] -1         # overriding Ki and Ko \n",
    "        X[:, 2] = X[:,0] -.2        \n",
    "        # print(X)\n",
    "        X[:, 1] += Xpre[:,1]        # adding back the offset in Xpre after it gets overrided\n",
    "        X[:, 2] += Xpre[:,2] \n",
    "\n",
    "        # making sure self.snowball_path_holder is zeroed to avoid bug\n",
    "        self.snowball_path_holder.fill(0)\n",
    "\n",
    "                                        # d_s, s_0, Ki, Ko, mu, sigma, pot,r,\n",
    "                                        # d_normals, snowball_path_holder, MONTHS,\n",
    "                                        # N_STEPS, N_PATHS, N_BATCH):\n",
    "        monte_carlo_andtheholygrail_gpu[(self.num_blocks,), (self.num_threads,)](\n",
    "                                        self.output, X[:, 0], X[:, 1], X[:, 2], X[:, 3], \n",
    "                                        X[:, 4], X[:, 5], X[:, 6],\n",
    "                                        randoms, self.snowball_path_holder, self.MONTHS,\n",
    "                                        self.N_STEPS, self.N_PATHS, self.N_BATCH)\n",
    "        \n",
    "        o = self.output.reshape(self.N_BATCH, self.N_PATHS)\n",
    "        Y  =o.mean(axis =1)         # getting the average of each batch\n",
    "        self.num+=1\n",
    "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now a small test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SnowballDataSet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ds = SnowballDataSet(10, number_path=500000, batch=16, seed=15)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ds \u001b[38;5;241m=\u001b[39m SnowballDataSet(\u001b[38;5;241m10\u001b[39m, number_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500000\u001b[39m, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ds:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# print(i, \"\\n\")\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i[\u001b[38;5;241m0\u001b[39m],i[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SnowballDataSet' is not defined"
     ]
    }
   ],
   "source": [
    "# ds = SnowballDataSet(10, number_path=500000, batch=16, seed=15)\n",
    "ds = SnowballDataSet(10, number_path=500000, batch=1, seed=15)\n",
    "for i in ds:\n",
    "    # print(i, \"\\n\")\n",
    "    print(i[0],i[1])     # printing the Ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "Erm pretty default model. Just making it have functionality. normalizing it accoriding to the average value of all of the input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting snow_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile snow_model.py\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden=1024):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(7, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, hidden)\n",
    "        self.fc4 = nn.Linear(hidden, hidden)\n",
    "        self.fc5 = nn.Linear(hidden, hidden)\n",
    "        self.fc6 = nn.Linear(hidden, hidden)\n",
    "        self.fc7 = nn.Linear(hidden, 1)\n",
    "        self.register_buffer('norm',\n",
    "                             torch.tensor([10.0,\n",
    "                                           8.5,\n",
    "                                           10.4,\n",
    "                                           0.025,\n",
    "                                           0.35,\n",
    "                                           20,\n",
    "                                           0.025]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # normalize the parameter to range [0-1] \n",
    "        x = x / self.norm           # normalizing params makes for higher accuracy\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = F.elu(self.fc3(x))\n",
    "        x = F.elu(self.fc4(x))\n",
    "        x = F.elu(self.fc5(x))\n",
    "        x = F.elu(self.fc6(x))\n",
    "        return self.fc7(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model\n",
    "as the amount of data is relatively small, a smallish batch size will be used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda:0\n",
      "2998535\n",
      "loss 0.22300417721271515 average time 0.002368915173364407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[166], line 88\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Error: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAvg loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m>8f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;66;03m# @trainer.on(Events.GET_BATCH_STARTED)\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# def log_training_loss(engine):\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m#     print(\"EPOCH!!!!!!!!!!!!\\n\")\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m trainer\u001b[38;5;241m.\u001b[39mrun(tr_loader, max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:889\u001b[0m, in \u001b[0;36mEngine.run\u001b[1;34m(self, data, max_epochs, epoch_length)\u001b[0m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run()\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:932\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator)\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:990\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 990\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(e)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:956\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[1;32m--> 956\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[0;32m    958\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:1077\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_STARTED)\n\u001b[0;32m   1075\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[1;32m-> 1077\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_function(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch)\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mITERATION_COMPLETED)\n\u001b[0;32m   1079\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n",
      "Cell \u001b[1;32mIn[166], line 39\u001b[0m, in \u001b[0;36mtrain_update\u001b[1;34m(engine, batch)\u001b[0m\n\u001b[0;32m     36\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred[:,\u001b[38;5;241m0\u001b[39m], y)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;66;03m# assert y_pred.dtype is torch.float16 ##################\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# assert loss.dtype is torch.float32 ##################\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     40\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m     41\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    527\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m _engine_run_backward(\n\u001b[0;32m    268\u001b[0m     tensors,\n\u001b[0;32m    269\u001b[0m     grad_tensors_,\n\u001b[0;32m    270\u001b[0m     retain_graph,\n\u001b[0;32m    271\u001b[0m     create_graph,\n\u001b[0;32m    272\u001b[0m     inputs,\n\u001b[0;32m    273\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    274\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    275\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    745\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    746\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import Timer\n",
    "\n",
    "from ignite.handlers import CosineAnnealingScheduler\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "# from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler    # defunct\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from torch.cuda import amp       # apex.amp is deprecated. it cannot be regenerated.\n",
    "\n",
    "from snow_model import Net\n",
    "# from snow_model_module import Net\n",
    "# from snow_model_2 import Net\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device used : {device}\")\n",
    "\n",
    "# from cupy_dataset import OptionDataSet\n",
    "timer = Timer(average=True)\n",
    "model = Net().cuda()\n",
    "loss_fn = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "set_amp = True\n",
    "scaler = amp.GradScaler(enabled=set_amp)\n",
    "\n",
    "def train_update(engine, batch):\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16): ########### automatic mixed precision\n",
    "        model.train()\n",
    "        # optimizer.zero_grad()\n",
    "        optimizer.zero_grad(set_to_none=True) # set_to_none=True here can modestly improve performance \n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred[:,0], y)\n",
    "        # assert y_pred.dtype is torch.float16 ##################\n",
    "        # assert loss.dtype is torch.float32 ##################\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True) # set_to_none=True here can modestly improve performance \n",
    "    # optimizer.zero_grad()\n",
    "    return loss.item()\n",
    "\n",
    "print(len(tr_loader.dataset))\n",
    "trainer = Engine(train_update)\n",
    "# log_interval = 1000\n",
    "interval_count  = 5\n",
    "log_interval = len(tr_loader.dataset)//batch_size//interval_count\n",
    "\n",
    "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(tr_loader))   # length of a batch\n",
    "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)  ## restarts the learning rate of cosine; each iteration is 1 batch long\n",
    "timer.attach(trainer,\n",
    "             start=Events.EPOCH_STARTED,\n",
    "             resume=Events.ITERATION_STARTED,\n",
    "             pause=Events.ITERATION_COMPLETED,\n",
    "             step=Events.ITERATION_COMPLETED)    \n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iter = (engine.state.iteration - 1) % len(tr_loader) + 1\n",
    "    if iter % log_interval == 0:\n",
    "        print('loss', engine.state.output, 'average time', timer.value())\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_test_loss(engine):\n",
    "    size = len(te_loader.dataset)\n",
    "    num_batches = len(te_loader)\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    with torch.no_grad():\n",
    "        for X,y in te_loader:\n",
    "            # X,y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred[:,0],y).item() #item converts tensor to number\n",
    "            # print(y)\n",
    "            # print(pred)       # has some interesting results showing how argmax\n",
    "            # print(test_loss)\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\nAvg loss: {test_loss:>8f}\\n\")\n",
    "\n",
    "# @trainer.on(Events.GET_BATCH_STARTED)\n",
    "# def log_training_loss(engine):\n",
    "#     print(\"EPOCH!!!!!!!!!!!!\\n\")\n",
    "        \n",
    "trainer.run(tr_loader, max_epochs=5)\n",
    "# trainer.run(dataset, max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An equivalent run using nn.Sequential for funsies. <br>\n",
    "nn.Module is also included for a trainerless comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "hidden = 1024\n",
    "\n",
    "mai_normals = [10.0, 8.5,10.4, 0.025, 0.35, 20, 0.025]\n",
    "cuda0 = torch.device(\"cuda:0\")\n",
    "\n",
    "class Normalizer(nn.Module):\n",
    "    def __init__(self, normals):\n",
    "        super(Normalizer,self).__init__()\n",
    "        self.norms = torch.tensor(normals, device=cuda0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x / self.norms\n",
    "        # print(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model_o = nn.Sequential(\n",
    "    Normalizer(mai_normals),\n",
    "    nn.Linear(7, hidden),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(hidden, hidden),          #\n",
    "    nn.ELU(),                           # nn.ELU used for sequential\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(hidden, hidden),\n",
    "    nn.ELU(),\n",
    "    nn.Linear(hidden, 1),\n",
    "    nn.ELU(),\n",
    "    ).cuda()\n",
    "\n",
    "class Neth(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden=1024):\n",
    "        super(Neth, self).__init__()\n",
    "        self.fc1 = nn.Linear(7, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, hidden)\n",
    "        self.fc4 = nn.Linear(hidden, hidden)\n",
    "        self.fc5 = nn.Linear(hidden, hidden)\n",
    "        self.fc6 = nn.Linear(hidden, hidden)\n",
    "        self.fc7 = nn.Linear(hidden, 1)\n",
    "        self.register_buffer('norm',\n",
    "                             torch.tensor([10.0,\n",
    "                                           8.5,\n",
    "                                           10.4,\n",
    "                                           0.025,\n",
    "                                           0.35,\n",
    "                                           20,\n",
    "                                           0.025]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # normalize the parameter to range [0-1] \n",
    "        x = x / self.norm           # normalizing params makes for higher accuracy\n",
    "        # print(x)\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = F.elu(self.fc3(x))      # F.elu used for forward\n",
    "        x = F.elu(self.fc4(x))\n",
    "        x = F.elu(self.fc5(x))\n",
    "        x = F.elu(self.fc6(x))\n",
    "        return self.fc7(x)\n",
    "    \n",
    "model_h = Neth().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda:0\n",
      "loss: 11.361467 [100]\n",
      "loss: 0.737593 [100100]\n",
      "loss: 1.192102 [200100]\n",
      "loss: 0.695697 [300100]\n",
      "loss: 0.792687 [400100]\n",
      "loss: 0.667904 [500100]\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "\n",
    "loss_fn = MSELoss()\n",
    "optimizer = Adam(model_h.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(te_loader), 1e-6, )\n",
    "scheduler2 = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(te_loader))\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device used : {device}\")\n",
    "\n",
    "\n",
    "for ep in range(epoch):\n",
    "    model_h.train()\n",
    "    for batch, (x,y) in enumerate(te_loader):\n",
    "        # x, y = x.to(device), y.to(device)\n",
    "        pred = model_h(x)\n",
    "        loss = loss_fn( y, pred)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch %1000 ==0:\n",
    "            loss, current = loss.item(), (batch+1)*len(x)\n",
    "            print(f\"loss: {loss:>7f} [{current}]\")\n",
    "\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us test how good our model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      "Avg loss: 0.014540\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "size = len(val_loader.dataset)\n",
    "num_batches = len(val_loader)\n",
    "model.eval()\n",
    "test_loss=0\n",
    "with torch.no_grad():\n",
    "    for X,y in val_loader:\n",
    "        # X,y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        test_loss += loss_fn(pred[:,0],y).item() #item converts tensor to number\n",
    "        # print(y)\n",
    "        # print(pred[:,0])       # has some interesting results showing how argmax\n",
    "        # print(test_loss)\n",
    "test_loss /= num_batches\n",
    "print(f\"Test Error: \\nAvg loss: {test_loss:>8f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the validation result is pretty close to test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tryhard Mode\n",
    "hopefully i am comptent at coding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda:0\n",
      "loss 0.2461223602294922 average time 0.00244426386584527\n",
      "loss 0.1531197726726532 average time 0.002620185367739437\n",
      "loss 0.2145565301179886 average time 0.002645124506855398\n",
      "loss 0.08563321083784103 average time 0.0025858514132854034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[172], line 102\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoctr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m â†‘\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# @trainer.on(Events.GET_BATCH_STARTED)\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# def log_training_loss(engine):\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m#     print(\"EPOCH!!!!!!!!!!!!\\n\")\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m trainer\u001b[38;5;241m.\u001b[39mrun(tr_loader, max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:889\u001b[0m, in \u001b[0;36mEngine.run\u001b[1;34m(self, data, max_epochs, epoch_length)\u001b[0m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterrupt_resume_enabled:\n\u001b[1;32m--> 889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run()\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_legacy()\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:932\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_as_gen()\n\u001b[0;32m    931\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator)\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[0;32m    934\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_run_generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:990\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    988\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine run is terminating due to exception: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 990\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_exception(e)\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:644\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 644\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:956\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_engine()\n\u001b[1;32m--> 956\u001b[0m epoch_time_taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[0;32m    958\u001b[0m \u001b[38;5;66;03m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[0;32m    959\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimes[Events\u001b[38;5;241m.\u001b[39mEPOCH_COMPLETED\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m epoch_time_taken\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\ignite\\engine\\engine.py:1033\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1030\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_event(Events\u001b[38;5;241m.\u001b[39mGET_BATCH_STARTED)\n\u001b[0;32m   1031\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[1;32m-> 1033\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataloader_iter)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m# We should not trigger GET_BATCH_STARTED, GET_BATCH_COMPLETED, DATALOADER_STOP_ITERATION events\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# if no data was provided to engine.run(data=None, ...)\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:627\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 627\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_name):\n\u001b[0;32m    628\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\torch\\autograd\\profiler.py:610\u001b[0m, in \u001b[0;36mrecord_function.__exit__\u001b[1;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39m_record_function_enter_new(\n\u001b[0;32m    606\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[0;32m    607\u001b[0m     )\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m--> 610\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any):\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks_on_exit:\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import Timer\n",
    "import torch\n",
    "import ignite\n",
    "from ignite.handlers import CosineAnnealingScheduler\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "# from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler    # defunct\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from torch.cuda import amp       # apex.amp is deprecated. it cannot be regenerated.\n",
    "\n",
    "from snow_model import Net\n",
    "# from snow_model_module import Net\n",
    "# from snow_model_2 import Net\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device used : {device}\")\n",
    "\n",
    "# from cupy_dataset import OptionDataSet\n",
    "timer = Timer(average=True)\n",
    "model = Net().cuda()\n",
    "loss_fn = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "set_amp = True\n",
    "scaler = amp.GradScaler(enabled=set_amp)\n",
    "\n",
    "epoctr = 1\n",
    "### model resumer (in case fucky wucky happens and model crashes)\n",
    "        # will write later\n",
    "\n",
    "\n",
    "### model training method for ~~tammy~~ ENGINE\n",
    "def train_update(engine, batch):\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16): ########### automatic mixed precision\n",
    "        model.train()\n",
    "        # optimizer.zero_grad()\n",
    "        optimizer.zero_grad(set_to_none=True) # set_to_none=True here can modestly improve performance \n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred[:,0], y)\n",
    "        # assert y_pred.dtype is torch.float16 ##################\n",
    "        # assert loss.dtype is torch.float32 ##################\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True) # set_to_none=True here can modestly improve performance \n",
    "    # optimizer.zero_grad()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(train_update)\n",
    "interval_count  = 5     # how many times loss message shows up every epoch\n",
    "log_interval = len(tr_loader.dataset)//batch_size//interval_count\n",
    "\n",
    "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(tr_loader))\n",
    "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)  ## restarts the learning rate of cosine; each iteration is 1 batch long\n",
    "# trainer add events, attach metrics & others\n",
    "\n",
    "timer.attach(trainer,                       ##\n",
    "             start=Events.EPOCH_STARTED,\n",
    "             resume=Events.ITERATION_STARTED,\n",
    "             pause=Events.ITERATION_COMPLETED,\n",
    "             step=Events.ITERATION_COMPLETED)    \n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iter = (engine.state.iteration - 1) % len(tr_loader) + 1\n",
    "    if iter % log_interval == 0:\n",
    "        print('loss', engine.state.output, 'average time', timer.value())\n",
    "\n",
    "\n",
    "loss_m = ignite.metrics.Loss(loss_fn)\n",
    "best_loss = 99.0\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_test_loss(engine):\n",
    "    global best_loss\n",
    "    size = len(te_loader.dataset)\n",
    "    num_batches = len(te_loader)\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    with torch.no_grad():\n",
    "        for X,y in te_loader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred[:,0],y).item() #item converts tensor to number\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f}\")\n",
    "    if best_loss > test_loss:\n",
    "        print(f\"new best model saved, UWU\\n{best_loss}->{test_loss}\")\n",
    "        best_loss = test_loss\n",
    "        torch.save(model.state_dict(), \"saved_model/model_weights.pth\")\n",
    "    \n",
    "    print(f\"Epoch: {epoctr} â†‘\\n\")\n",
    "\n",
    "# @trainer.on(Events.GET_BATCH_STARTED)\n",
    "# def log_training_loss(engine):\n",
    "#     print(\"EPOCH!!!!!!!!!!!!\\n\")\n",
    "        \n",
    "trainer.run(tr_loader, max_epochs=1000)\n",
    "# trainer.run(dataset, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import Timer\n",
    "import torch\n",
    "import ignite\n",
    "from ignite.handlers import CosineAnnealingScheduler\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "# from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler    # defunct\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from torch.cuda import amp       # apex.amp is deprecated. it cannot be regenerated.\n",
    "\n",
    "from snow_model import Net\n",
    "# from snow_model_module import Net\n",
    "# from snow_model_2 import Net\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device used : {device}\")\n",
    "\n",
    "# from cupy_dataset import OptionDataSet\n",
    "timer = Timer(average=True)\n",
    "model = Net().cuda()\n",
    "loss_fn = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "set_amp = True\n",
    "scaler = amp.GradScaler(enabled=set_amp)\n",
    "\n",
    "epoctr = 1\n",
    "### model resumer (in case fucky wucky happens and model crashes)\n",
    "        # will write later\n",
    "\n",
    "\n",
    "### model training method for ~~tammy~~ ENGINE\n",
    "def train_update(engine, batch):\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16): ########### automatic mixed precision\n",
    "        model.train()\n",
    "        # optimizer.zero_grad()\n",
    "        optimizer.zero_grad(set_to_none=True) # set_to_none=True here can modestly improve performance \n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred[:,0], y)\n",
    "        # assert y_pred.dtype is torch.float16 ##################\n",
    "        # assert loss.dtype is torch.float32 ##################\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True) # set_to_none=True here can modestly improve performance \n",
    "    # optimizer.zero_grad()\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(train_update)\n",
    "interval_count  = 5     # how many times loss message shows up every epoch\n",
    "log_interval = len(tr_loader.dataset)//batch_size//interval_count\n",
    "\n",
    "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-5, 1e-6, len(tr_loader))\n",
    "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)  ## restarts the learning rate of cosine; each iteration is 1 batch long\n",
    "# trainer add events, attach metrics & others\n",
    "\n",
    "timer.attach(trainer,                       ##\n",
    "             start=Events.EPOCH_STARTED,\n",
    "             resume=Events.ITERATION_STARTED,\n",
    "             pause=Events.ITERATION_COMPLETED,\n",
    "             step=Events.ITERATION_COMPLETED)    \n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iter = (engine.state.iteration - 1) % len(tr_loader) + 1\n",
    "    if iter % log_interval == 0:\n",
    "        print('loss', engine.state.output, 'average time', timer.value())\n",
    "\n",
    "\n",
    "loss_m = ignite.metrics.Loss(loss_fn)\n",
    "best_loss = 99.0\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_test_loss(engine):\n",
    "    global best_loss\n",
    "    size = len(te_loader.dataset)\n",
    "    num_batches = len(te_loader)\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    with torch.no_grad():\n",
    "        for X,y in te_loader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred[:,0],y).item() #item converts tensor to number\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Avg loss: {test_loss:>8f}\")\n",
    "    if best_loss > test_loss:\n",
    "        print(f\"new best model saved, UWU\\n{best_loss}->{test_loss}\")\n",
    "        best_loss = test_loss\n",
    "        torch.save(model.state_dict(), \"saved_model/model_weights2.pth\")\n",
    "    \n",
    "    print(f\"Epoch: {epoctr} â†‘\\n\")\n",
    "\n",
    "# @trainer.on(Events.GET_BATCH_STARTED)\n",
    "# def log_training_loss(engine):\n",
    "#     print(\"EPOCH!!!!!!!!!!!!\\n\")\n",
    "        \n",
    "trainer.run(tr_loader, max_epochs=1000)\n",
    "# trainer.run(dataset, max_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nah, id lose\n",
    "stuff is still not finished yet :/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = pics\\galaxy-angel-mint-blancmanche.gif>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on the bright side, that means theres more to come! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=pics/reisen-udongein.gif width = 500>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
