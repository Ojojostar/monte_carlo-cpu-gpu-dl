{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep learning model time!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<img src = pics/OIP.jpg width = 400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "cupy.cuda.set_allocator(None)       # no clue\n",
    "from torch.utils.dlpack import from_dlpack\n",
    "\n",
    "import numba\n",
    "from numba import cuda\n",
    "\n",
    "import os, os.path\n",
    "from pathlib import Path\n",
    "from torch import cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataset\n",
    "Each monte carlo simulation run is equivalent to one data point being made, so to generate a large dataset, we have to run monte carlo simulations lots of times, and batches can hypotheitcally make doing this faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here,the mc model from mc_snow, cuda version was imported and cleaned up a bit.\n",
    "note that due to the existence of batches, some of the varaibles now need a bit of extra finagling to access properly. (s_0, Ki, Ko, mu, sigma, pot,r, d_normals, snowball_path_holder). Overall design is very close to original, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit               # defualt GPU\n",
    "def monte_carlo_andtheholygrail_gpu(d_s, s_0, Ki, Ko, mu, sigma, pot,r,\n",
    "                                    d_normals, snowball_path_holder, MONTHS,\n",
    "                                    N_STEPS, N_PATHS, N_BATCH):\n",
    "    \n",
    "\n",
    "    # for shared memory (non)optimization\n",
    "    # shared = cuda.shared.array(shape=0, dtype=numba.float32)\n",
    "    # # load to shared memory\n",
    "    # path_offset = cuda.blockIdx.x * cuda.blockDim.x\n",
    "\n",
    "    # ii - overall thread index\n",
    "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
    "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
    "\n",
    "    for n in range(ii, N_PATHS * N_BATCH, stride):\n",
    "        # newly added vars for N_BATCH calculations\n",
    "        batch_id = n // N_PATHS\n",
    "        path_id = n % N_PATHS       # equivalent to n in old code \n",
    "\n",
    "        snowball_path_holder[n][0] = s_0[batch_id]\n",
    "        earlyexit = False\n",
    "        ki = False\n",
    "        mald = False\n",
    "        for t in range(N_STEPS):\n",
    "            # pre shared memory b_motion    \n",
    "            #                                                   \n",
    "            b_motion = d_normals[path_id + batch_id * N_PATHS +  t * N_PATHS * N_BATCH]\n",
    "\n",
    "            # post shared memory b_motion\n",
    "            # shared[cuda.threadIdx.x] = d_normals[path_offset + cuda.threadIdx.x + t * N_PATHS]\n",
    "\n",
    "            dt = 1/N_STEPS\n",
    "            # pre shared memory b_motion\n",
    "            ds = snowball_path_holder[n][t] * mu[batch_id] * dt + snowball_path_holder[n][t] \\\n",
    "                                                * sigma[batch_id] * b_motion * math.sqrt(dt) \n",
    "            # post shared memory b_motion\n",
    "            # ds = snowball_path_holder[n][t] * mu[batch_id] * dt + snowball_path_holder[n][t] * sigma[batch_id] * shared[cuda.threadIdx.x] * math.sqrt(dt) \n",
    "                    # no adjusting list sizes in cuda :(\n",
    "            # snowball_path.append(snowball_path[t]+ds)\n",
    "            snowball_path_holder[n][t+1] = snowball_path_holder[n][t] + ds\n",
    "            \n",
    "\n",
    "            # ki = snowball_path[t] + ds\n",
    "            if snowball_path_holder[n][t+1] <= Ki[batch_id]:\n",
    "                ki = True\n",
    "\n",
    "            if not mald:\n",
    "                for month in (0,1,2,3,4,5,6,7,8,9,10,11):                # need to do this instead because contains (in) and range are disabled\n",
    "                    if t+1 == MONTHS[month]:     #startday no longer used to fake a start date in code\n",
    "                        # price = t+1+startday\n",
    "                        if snowball_path_holder[n][t+1] >= Ko[batch_id]:\n",
    "                            price =  pot[batch_id] * t/365     # should turn t into int\n",
    "                            # return snowball_path, price\n",
    "                            d_s[n] =  price * math.exp(-r[batch_id] * t/N_STEPS)   # accounting for r\n",
    "                            snowball_path_holder[n][-1] = d_s[n]            \n",
    "                            earlyexit = True\n",
    "                            mald = True\n",
    "                            # print(\"blo got fucked\\n\")\n",
    "                            break\n",
    "            else: # if mald\n",
    "                break\n",
    "        \n",
    "        if not earlyexit:       # to prevent early exit getting out of bdds error\n",
    "            # did not get knocked up or down\n",
    "            price = pot[batch_id]\n",
    "            # t  =T \n",
    "                        # CAN'T USE T CUZ CUDA IS FUCKING SHIT so use -1 instead\n",
    "                        # or not ig T works now :sob:\n",
    "            if ki and snowball_path_holder[n][N_STEPS] <= s_0[batch_id]:          # blo got knocked down and never recovered\n",
    "                price = snowball_path_holder[n][N_STEPS] - s_0[batch_id]\n",
    "            elif ki and snowball_path_holder[n][N_STEPS] <= Ko[batch_id]:          # blo got knocked down for a bit but finished above Ki\n",
    "                price =0\n",
    "            d_s[n] = price * math.exp(-r[batch_id])\n",
    "            snowball_path_holder[n][-1] = d_s[n]    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, for some reason, increasing the number of paths and/or the number of batches greatly slows down my monte's carlo's computational speed. I have no definitive proof that this is the case, but I strongly belive it to be because threads are becoming unsynched as the code runs on, making both greater paths and greater batches than my current settings have much slower run times than their current values. Not that my current code isn't slower than it should be, either. <br>\n",
    " Max len controls the number of data points, path controls how accurate each data point is. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished running, data is saved into a directory.\n",
    "<br>\n",
    "If you think running a large number like 1 mil mcs takes way too long, throw these first three cells into a python file (datasetgen.py) and let it run in its own terminal while going forward in the notebook with a smaller set for test purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for demonstration purposes, only a small amount of data is generated here. If large amounts of data are to be generated, **PLEASE** go to datasetgen.py instead. there is much more stuff there that isnt incorporated here since i dont like scrolling htat much that would make generating data a bit easier (generates data in chunks so that its safer, ability to run mutliple process of program at the same time thru currnumm)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute '_sanitizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m num_blocks  \u001b[38;5;241m=\u001b[39m(N_PATHS \u001b[38;5;241m*\u001b[39m N_BATCH \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m threads \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     32\u001b[0m num_threads \u001b[38;5;241m=\u001b[39m threads\n\u001b[1;32m---> 34\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_sanitizer\u001b[38;5;241m.\u001b[39menable_cuda_sanitizer()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Xs =  np.zeros(max_length, dtype=(np.float32,7))#\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Ys =  np.zeros(max_length, dtype=(np.float32))#          storing final data\u001b[39;00m\n\u001b[0;32m     38\u001b[0m Xss \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute '_sanitizer'"
     ]
    }
   ],
   "source": [
    "#               make sure max_len is large enough or else divide by zero error occurs (at least 100 batches must be run)\n",
    "limiter = True\n",
    "# max_len = 1000000                 # hundo thousand data points, final speed is ~40 min for 1000 data.\n",
    "max_len = 10                 # hundo thousand data points, final speed is ~40 min for 1000 data.\n",
    "number_path = 500000\n",
    "batch = 1\n",
    "threads = 256\n",
    "seed  =1999 \n",
    "num = 0\n",
    "max_length = max_len\n",
    "N_PATHS = number_path\n",
    "N_STEPS = 365\n",
    "N_BATCH  =batch\n",
    "\n",
    "max_length = max_length // N_BATCH\n",
    "percenter  =100\n",
    "percent = max_length // percenter\n",
    "\n",
    "#           uncomment if u want less batches, the percent will just be wrong\n",
    "if percent == 0:\n",
    "    percent = 1\n",
    "\n",
    "# we will not be calculating a starting date since the difference is negligible and I aint rigging up\n",
    "# a system to check if a certain day is a weekend or not\n",
    "MONTHS = cupy.asnumpy([0, 31,59,90,120,151,181,212,243, 273,304,334])\n",
    "        # SHOULD THIS BE NP ARRAY INSTEAD????\n",
    "snowball_path_holder =  np.zeros(N_BATCH*N_PATHS, dtype=(np.float32,N_STEPS+1))# extra 1 is no longer for storing payoff\n",
    "# self.snowball_path_holder = cupy.array(self.snowball_path_holder)\n",
    "# self.T  = np.float(365.0)         # nah id lose. \n",
    "output = cupy.zeros(N_BATCH*N_PATHS, dtype = cupy.float32)\n",
    "num_blocks  =(N_PATHS * N_BATCH -1) // threads +1\n",
    "num_threads = threads\n",
    "\n",
    "torch.cuda._sanitizer.enable_cuda_sanitizer()\n",
    "# Xs =  np.zeros(max_length, dtype=(np.float32,7))#\n",
    "# Ys =  np.zeros(max_length, dtype=(np.float32))#          storing final data\n",
    "\n",
    "Xss = []\n",
    "Yss = []\n",
    "# Xss = np.zeros((max_length, 7))\n",
    "# Yss = np.zeros((max_length, 1))\n",
    "currnum = len(os.listdir('snow_data_tensor_train'))//2+1\n",
    "print(\"Adding files starting from\", currnum)\n",
    "\n",
    "print(\"Num batches:\", N_BATCH)\n",
    "\n",
    "# making sure self.snowball_path_holder is zeroed to avoid bug\n",
    "# self.snowball_path_holder.fill(0)\n",
    "s = time.time()\n",
    "\n",
    "for i in range(1,max_length+1):\n",
    "        randoms = cupy.random.normal(0,1, N_BATCH * N_PATHS * N_STEPS, dtype= cupy.float32)\n",
    "\n",
    "        Xpre = cupy.random.rand(N_BATCH, 7, dtype = cupy.float32)\n",
    "        #                        s_0,  Ki, Ko,  mu, sigma, pot, r\n",
    "        Xpre = Xpre * cupy.array([4,  -2,  1,  .01,  .15,  10, .01], dtype=cupy.float32)\n",
    "        X = Xpre +    cupy.array([8,   0,  0,  .02, .275,  15, .02], dtype=cupy.float32)\n",
    "        # Ki and Ko will be set down here instead of the previous line to make them relative to s_0.\n",
    "        X[:, 1] = X[:,0] -1         # overriding Ki and Ko \n",
    "        X[:, 2] = X[:,0] -.2        \n",
    "        X[:, 1] += Xpre[:,1]        # adding back the offset in Xpre after it gets overrided\n",
    "        X[:, 2] += Xpre[:,2] \n",
    "\n",
    "        snowball_path_holder.fill(0)\n",
    "                                        # d_s, s_0, Ki, Ko, mu, sigma, pot,r,\n",
    "                                        # d_normals, snowball_path_holder, MONTHS,\n",
    "                                        # N_STEPS, N_PATHS, N_BATCH):\n",
    "        monte_carlo_andtheholygrail_gpu[(num_blocks,), (num_threads,)](\n",
    "                                        output, X[:, 0], X[:, 1], X[:, 2], X[:, 3], \n",
    "                                        X[:, 4], X[:, 5], X[:, 6],\n",
    "                                        randoms, snowball_path_holder, MONTHS,\n",
    "                                        N_STEPS, N_PATHS, N_BATCH)\n",
    "        # o = output.reshape(N_BATCH, N_PATHS)\n",
    "        # Y  =o.mean(axis =1)         # getting the average of each batch\n",
    "        Y = output.mean()\n",
    "        X = X.mean(axis=0)\n",
    "        Xss.append(X.tolist())\n",
    "        Yss.append(Y.tolist())\n",
    "        # Xss.append(X)\n",
    "        # Yss.append(Y)\n",
    "\n",
    "        # have following turned off. go to datasetgen.py for a better view.\n",
    "        # if(i%percent==0):\n",
    "        #     if limiter:\n",
    "        #         if currnum > percenter:\n",
    "        #             print(\"premature exit, burunyu~\")\n",
    "        #             break\n",
    "        #     e = time.time()\n",
    "        #     print(i/(percent), \"percent of the way there! Time is now:\", (e-s)/60/60, \"hours\")\n",
    "        #     # print(i/(percent*10), \"percent of the way there! Time is now:\", e-s, \"secs\")\n",
    "        #     print(\"now saving tsnowX_{}.pt\".format(currnum) )\n",
    "        #     tensorX = np.array(Xss)\n",
    "        #     tensorY = np.array(Yss)\n",
    "        #     tensorX = torch.Tensor(tensorX)\n",
    "        #     tensorY = torch.Tensor(tensorY)\n",
    "        #     torch.save(tensorX, f\"snow_data_tensor_train/tsnowX_{currnum}.pt\")\n",
    "        #     torch.save(tensorY, f\"snow_data_tensor_train/tsnowY_{currnum}.pt\")\n",
    "        #     Xss.clear()\n",
    "        #     Yss.clear()\n",
    "        #     currnum += 1\n",
    "\n",
    "        num+=1          #actually useless\n",
    "        # print((from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))) \n",
    "\n",
    "v = output.mean()\n",
    "cuda.synchronize()\n",
    "e = time.time()\n",
    "print('time', e-s, 'v', v, 'avg time', (e-s)/500000)\n",
    "\n",
    "# Xs = np.array(Xss)\n",
    "# Ys = np.array(Yss)\n",
    "Xss = np.array(Xss)\n",
    "Yss = np.array(Yss)\n",
    "# print(Xss)\n",
    "print(Yss)\n",
    "\n",
    "tensorX = torch.Tensor(Xss)\n",
    "tensorY = torch.Tensor(Yss)\n",
    "print(tensorX)\n",
    "print(tensorY)\n",
    "\n",
    "## i have following turned off but feel free to do stuff with it\n",
    "\n",
    "# torch.save(tensorX, \"snow_data_tensor_train/tsnowX.pt\")\n",
    "# torch.save(tensorY, \"snow_data_tensor_train/tsnowY.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A small tangent on datasetgen\n",
    "So... after a lot of finagling with datasetgen.py, I have realized that it is most certianly the case that the code runs slower due to needing to run 500000 paths before it can synch back up again, causing great slowdown, espeicaly with larger batch/path numbers. However, this does not prevent us from running multiple different processes of the same code, filling up the gpu with power of more processes instead. Though there is some slowdown caused by having more processes, there is an almost 2 times improvement over runnign one process of the code when using 3 processes. Thats a lot! Of course, if you can get more processes runnign without gpu's memory going to 100% and locking up the program for extended periods of time, this should allow for as much speedup as you would get by using all of your gpu???? I think???? Ive been runnign datasetgen in its own power shells to prevent restarts of vs code from restarting it (pylance keeps crashing >:( ), but this can obviously be turned all into a single program that creates as many processes as you want! Therefore there is also datasetgen_multi.py which can do exactly that! its a slight modification of datasetgen.py but is a big quality of life update, greatly lowering the amount of power shells i need to open every time i run the program (u cant close em while they are runnign since they are locked in and dont like to stop at keyboard interrupts)\n",
    "\n",
    "<img src = pics\\big_scary_hacker_man.jpg width = 700> <br>\n",
    "\n",
    "**Fig 1. Me being big scary hacker man ðŸ˜±** (6 process was a mistake and now all of them are frozen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to regularly scheduled programming (loading dataset made by datasetgen.py)\n",
    "Loading the data to confirm its existence! turning it into gpu monsters to prepare for throwing it into model to train! can prolly be done be done before saving, thouhg :/ <br>\n",
    "oh well, it takes like no time to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torchvision import transforms, utils, datasets\n",
    "import os\n",
    "\n",
    "path = \"snow_data_tensor\"\n",
    "\n",
    "def npy_loader(path):\n",
    "    sample = torch.load(path)\n",
    "    return sample\n",
    "\n",
    "# dataset = datasets.DatasetFolder(\n",
    "#     root=path,\n",
    "#     loader=npy_loader,\n",
    "#     extensions=['.pt']\n",
    "#     )\n",
    "# tensor_x = torch.Tensor(Xss)\n",
    "# tensor_y = torch.Tensor(Yss)\n",
    "tensor_x = torch.load(\"snow_data_tensor/tsnowX.pt\")\n",
    "tensor_y = torch.load(\"snow_data_tensor/tsnowY.pt\")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "inputs = tensor_x.float().to(device)\n",
    "values = tensor_y.float().to(device)\n",
    "\n",
    "# tdataset = TensorDataset(tensor_x,tensor_y) # create your datset\n",
    "tdataset = TensorDataset(inputs,values) # create your datset\n",
    "\n",
    "# print(tensor_x)\n",
    "\n",
    "# print(tdataset)\n",
    "\n",
    "# for i in tdataset:\n",
    "# #     # print(i, \"\\n\")\n",
    "#     print(i)     # printing the Ys\n",
    "# print(len(dataset)/2)\n",
    "# print(dataset)\n",
    "# inputs = tensor_x.float().to(device)\n",
    "# # values = tensor_y.float().to(device)\n",
    "# print(f\"Input device is : cuda:{tensor_x.get_device()}\")\n",
    "# print(f\"Target value device is : cuda:{tensor_y.get_device()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for some reason, the guy who made the nvidia notebook decided it was a good idea to make the dataset generate itself while training, making the training process significantly slower than if the data was already prepared already. This works, but is not that good. I would not reccomend, 2/5 stars. <br>\n",
    "edit: he does it the better way in their next notbook :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SnowballDataSet(object):\n",
    "\n",
    "    def __init__(self, max_len = 10, number_path = 1000, batch = 2, threads = 512, seed  =1999 ):\n",
    "        self.num = 0\n",
    "        self.max_length = max_len\n",
    "        self.N_PATHS = number_path\n",
    "        self.N_STEPS = 365\n",
    "        self.N_BATCH  =batch\n",
    "        # we will not be calculating a starting date since the difference is negligible and I aint rigging up\n",
    "        # a system to check if a certain day is a weekend or not\n",
    "        self.MONTHS = cupy.asnumpy([0, 31,59,90,120,151,181,212,243, 273,304,334])\n",
    "                # SHOULD THIS BE NP ARRAY INSTEAD????\n",
    "        self.snowball_path_holder =  np.zeros(self.N_BATCH*self.N_PATHS, dtype=(np.float32,self.N_STEPS+1))# extra 1 is no longer for storing payoff\n",
    "        # self.snowball_path_holder = cupy.array(self.snowball_path_holder)\n",
    "        # self.T  = np.float(365.0)         # nah id lose. \n",
    "        self.output = cupy.zeros(self.N_BATCH*self.N_PATHS, dtype = cupy.float32)\n",
    "        self.num_blocks  =(self.N_PATHS * self.N_BATCH -1) // threads +1\n",
    "        self.num_threads = threads\n",
    "\n",
    "        #  temp_months, snowball_path_holder both added now\n",
    "        cupy.random.seed(seed)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.max_length\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.num = 0\n",
    "        return self\n",
    "\n",
    "    #   next basically takes the place of the cell running the mc. As such need to generate\n",
    "     # (d_s, s_0, Ki, Ko, mu, sigma,  pot,r, d_normals, snowball_path_holder, MONTHS, N_STEPS, N_PATHS, N_BATCH\n",
    "     # note that all but s_0, Ki, Ko, mu, sigma,  pot,r, d_normals have been generated in init due to their nonrandom nature\n",
    "    def __next__(self):\n",
    "        if self.num > self.max_length: \n",
    "            raise StopIteration      # nvidia notebook uses raise StopIteration here but p sure its deprecated???\n",
    "                                      # is used because return returns an extra None\n",
    "        # generating the variables\n",
    "        # d_normals\n",
    "        randoms = cupy.random.normal(0,1, self.N_BATCH * self.N_PATHS * self.N_STEPS, dtype= cupy.float32)\n",
    "\n",
    "        Xpre = cupy.random.rand(self.N_BATCH, 7, dtype = cupy.float32)\n",
    "        #                        s_0,  Ki, Ko,  mu, sigma, pot, r\n",
    "        Xpre = Xpre * cupy.array([4,  -2,  1,  .01,  .15,  10, .01], dtype=cupy.float32)\n",
    "        X = Xpre +    cupy.array([8,   0,  0,  .02, .275,  15, .02], dtype=cupy.float32)\n",
    "        \n",
    "        # Ki and Ko will be set down here instead of the previous line to make them relative to s_0.\n",
    "        X[:, 1] = X[:,0] -1         # overriding Ki and Ko \n",
    "        X[:, 2] = X[:,0] -.2        \n",
    "        # print(X)\n",
    "        X[:, 1] += Xpre[:,1]        # adding back the offset in Xpre after it gets overrided\n",
    "        X[:, 2] += Xpre[:,2] \n",
    "\n",
    "        # making sure self.snowball_path_holder is zeroed to avoid bug\n",
    "        self.snowball_path_holder.fill(0)\n",
    "\n",
    "                                        # d_s, s_0, Ki, Ko, mu, sigma, pot,r,\n",
    "                                        # d_normals, snowball_path_holder, MONTHS,\n",
    "                                        # N_STEPS, N_PATHS, N_BATCH):\n",
    "        monte_carlo_andtheholygrail_gpu[(self.num_blocks,), (self.num_threads,)](\n",
    "                                        self.output, X[:, 0], X[:, 1], X[:, 2], X[:, 3], \n",
    "                                        X[:, 4], X[:, 5], X[:, 6],\n",
    "                                        randoms, self.snowball_path_holder, self.MONTHS,\n",
    "                                        self.N_STEPS, self.N_PATHS, self.N_BATCH)\n",
    "        \n",
    "        o = self.output.reshape(self.N_BATCH, self.N_PATHS)\n",
    "        Y  =o.mean(axis =1)         # getting the average of each batch\n",
    "        self.num+=1\n",
    "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now a small test run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xyzqadmin\\anaconda3\\Lib\\site-packages\\numba\\cuda\\cudadrv\\devicearray.py:886: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.6349,  7.2834,  9.7545,  0.0287,  0.3059, 24.2591,  0.0276]],\n",
      "       device='cuda:0') tensor([3.9449], device='cuda:0')\n",
      "tensor([[ 8.6179,  6.7289,  8.7578,  0.0208,  0.2911, 19.6906,  0.0254]],\n",
      "       device='cuda:0') tensor([3.1118], device='cuda:0')\n",
      "tensor([[ 8.5157,  5.8327,  8.6394,  0.0262,  0.2960, 21.1468,  0.0275]],\n",
      "       device='cuda:0') tensor([4.7028], device='cuda:0')\n",
      "tensor([[ 8.8283,  7.1150,  8.9113,  0.0208,  0.3009, 18.3316,  0.0227]],\n",
      "       device='cuda:0') tensor([2.5807], device='cuda:0')\n",
      "tensor([[11.8870,  9.9710, 11.7828,  0.0285,  0.3634, 23.8967,  0.0244]],\n",
      "       device='cuda:0') tensor([2.9223], device='cuda:0')\n",
      "tensor([[11.4234,  9.4665, 11.8392,  0.0211,  0.3384, 19.8409,  0.0246]],\n",
      "       device='cuda:0') tensor([2.6680], device='cuda:0')\n",
      "tensor([[11.0768,  8.6847, 11.8625,  0.0211,  0.3254, 20.9236,  0.0287]],\n",
      "       device='cuda:0') tensor([3.6412], device='cuda:0')\n",
      "tensor([[11.1044,  9.8112, 11.2277,  0.0231,  0.3005, 19.0593,  0.0228]],\n",
      "       device='cuda:0') tensor([2.5344], device='cuda:0')\n",
      "tensor([[ 8.2412,  6.8798,  8.8896,  0.0224,  0.3100, 19.8843,  0.0288]],\n",
      "       device='cuda:0') tensor([3.4307], device='cuda:0')\n",
      "tensor([[11.8692,  9.9715, 11.9518,  0.0266,  0.3321, 16.4964,  0.0255]],\n",
      "       device='cuda:0') tensor([1.9685], device='cuda:0')\n",
      "tensor([[ 8.5575,  6.9491,  8.6427,  0.0299,  0.3498, 18.2971,  0.0205]],\n",
      "       device='cuda:0') tensor([2.4426], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# ds = SnowballDataSet(10, number_path=500000, batch=16, seed=15)\n",
    "ds = SnowballDataSet(10, number_path=500000, batch=1, seed=15)\n",
    "for i in ds:\n",
    "    # print(i, \"\\n\")\n",
    "    print(i[0],i[1])     # printing the Ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the model\n",
    "\n",
    "Erm pretty default model. Just making it have functionality. normalizing it accoriding to the average value of all of the input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting snow_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile snow_model.py\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden=1024):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(7, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, hidden)\n",
    "        self.fc4 = nn.Linear(hidden, hidden)\n",
    "        self.fc5 = nn.Linear(hidden, hidden)\n",
    "        self.fc6 = nn.Linear(hidden, hidden)\n",
    "        self.fc7 = nn.Linear(hidden, 1)\n",
    "        self.register_buffer('norm',\n",
    "                             torch.tensor([10.0,\n",
    "                                           8.5,\n",
    "                                           10.4,\n",
    "                                           0.025,\n",
    "                                           0.35,\n",
    "                                           0.20,\n",
    "                                           0.025]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # normalize the parameter to range [0-1] \n",
    "        x = x / self.norm\n",
    "        x = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(x))\n",
    "        x = F.elu(self.fc3(x))\n",
    "        x = F.elu(self.fc4(x))\n",
    "        x = F.elu(self.fc5(x))\n",
    "        x = F.elu(self.fc6(x))\n",
    "        return self.fc7(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model\n",
    "now since we are running 500000 paths, our mc model results are only accurate to the dime, and can't partiucalry get the cents properly. As such, this calls for using a larger batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 1000\n",
       "\tepoch: 100\n",
       "\tepoch_length: 10\n",
       "\tmax_epochs: 100\n",
       "\toutput: 0.6449705362319946\n",
       "\tbatch: <class 'list'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.handlers import Timer\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import Adam\n",
    "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from torch.cuda import amp       # apex.amp is deprecated. it cannot be regenerated.\n",
    "\n",
    "from snow_model import Net\n",
    "# from snow_model_module import Net\n",
    "# from snow_model_2 import Net\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device used : {device}\")\n",
    "\n",
    "# from cupy_dataset import OptionDataSet\n",
    "timer = Timer(average=True)\n",
    "model = Net().cuda()\n",
    "loss_fn = MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "set_amp = True\n",
    "scaler = amp.GradScaler(enabled=set_amp)\n",
    "\n",
    "# dataset = OptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n",
    "# dataset = SnowballDataSet(max_len = 50000, number_path = 500000, batch = 4, threads = 512, seed  =1999 )\n",
    "# dataset = datasets.DatasetFolder(\n",
    "#     root=path,\n",
    "#     loader=npy_loader,\n",
    "#     extensions=['.pt']\n",
    "# )\n",
    "# dataset = atDataset()\n",
    "dataset = DataLoader(tdataset, 1000)\n",
    "\n",
    "# dataset size is 10,000\n",
    "def train_update(engine, batch):\n",
    "    with torch.autocast(device_type='cuda', dtype=torch.float16): ########### automatic mixed precision\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred[:,0], y)\n",
    "        assert y_pred.dtype is torch.float16 ##################\n",
    "        assert loss.dtype is torch.float32 ##################\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "    optimizer.zero_grad() # set_to_none=True here can modestly improve performance  WHAET DOES THIS DO\n",
    "    return loss.item()\n",
    "\n",
    "trainer = Engine(train_update)\n",
    "log_interval = 100\n",
    "\n",
    "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
    "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
    "timer.attach(trainer,\n",
    "             start=Events.EPOCH_STARTED,\n",
    "             resume=Events.ITERATION_STARTED,\n",
    "             pause=Events.ITERATION_COMPLETED,\n",
    "             step=Events.ITERATION_COMPLETED)    \n",
    "@trainer.on(Events.ITERATION_COMPLETED)\n",
    "def log_training_loss(engine):\n",
    "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
    "    if iter % log_interval == 0:\n",
    "        print('loss', engine.state.output, 'average time', timer.value())\n",
    "\n",
    "# @trainer.on(Events.GET_BATCH_STARTED)\n",
    "# def log_training_loss(engine):\n",
    "#     print(\"EPOCH!!!!!!!!!!!!\\n\")\n",
    "        \n",
    "# trainer.run(dataset, max_epochs=100)\n",
    "trainer.run(dataset, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(in_size, out_size, hidden,  num_layers):\n",
    "    layers = []\n",
    "    layers.append(torch.nn.Linear(in_size, hidden))\n",
    "    layers.append(torch.nn.functional.elu())\n",
    "    for _ in range(num_layers - 1):\n",
    "        layers.append(torch.nn.Linear(hidden, hidden))\n",
    "        layers.append(torch.nn.functional.elu())\n",
    "    layers.append(torch.nn.Linear(hidden, out_size))\n",
    "    return torch.nn.Sequential(*tuple(layers)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nah, id lose, and lose bad\n",
    "cudf is not supported on windows :/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = pics\\galaxy-angel-mint-blancmanche.gif>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dask_cudf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\n\u001b[0;32m      2\u001b[0m dask\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mset({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataframe.backend\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcudf\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdask_cudf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdelayed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m delayed\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdask_cuda\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocalCUDACluster\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dask_cudf'"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "dask.config.set({\"dataframe.backend\": \"cudf\"})\n",
    "import dask_cudf\n",
    "from dask.delayed import delayed\n",
    "from dask_cuda import LocalCUDACluster\n",
    "cluster = LocalCUDACluster()\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
